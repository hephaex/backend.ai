# Backend.AI KubeVirt GPU Deployment Guide

## ğŸ“‹ Overview

ì´ ê°€ì´ë“œëŠ” KubeVirtë¥¼ ì‚¬ìš©í•˜ì—¬ ë¬¼ë¦¬ì  GPU ì„œë²„ë¥¼ ê°€ìƒë¨¸ì‹ ìœ¼ë¡œ êµ¬ì„±í•˜ê³ , ê·¸ ìœ„ì— Backend.AI Agentë¥¼ ë°°í¬í•˜ì—¬ Backend.AI Managerì™€ ì—°ë™í•˜ëŠ” ë°©ë²•ì„ ì„¤ëª…í•©ë‹ˆë‹¤.

### ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        Kubernetes Cluster                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  KubeVirt Infrastructure                                            â”‚
â”‚  â”œâ”€â”€ KubeVirt Operator                                              â”‚
â”‚  â”œâ”€â”€ Containerized Data Importer (CDI)                             â”‚
â”‚  â”œâ”€â”€ NVIDIA GPU Operator                                            â”‚
â”‚  â””â”€â”€ GPU Device Plugins                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Backend.AI Manager (backend-ai namespace)                         â”‚
â”‚  â”œâ”€â”€ Manager Pod                                                   â”‚
â”‚  â”œâ”€â”€ ETCD                                                          â”‚
â”‚  â”œâ”€â”€ PostgreSQL                                                    â”‚
â”‚  â””â”€â”€ Redis                                                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  GPU Agent VMs (backend-ai-gpu namespace)                          â”‚
â”‚  â”œâ”€â”€ VM 1: backend-ai-gpu-agent-001                               â”‚
â”‚  â”‚   â”œâ”€â”€ GPU Passthrough (NVIDIA A10)                             â”‚
â”‚  â”‚   â”œâ”€â”€ Backend.AI Agent Service                                 â”‚
â”‚  â”‚   â”œâ”€â”€ Docker + NVIDIA Container Toolkit                       â”‚
â”‚  â”‚   â””â”€â”€ Network: Pod + Management                                â”‚
â”‚  â”œâ”€â”€ VM 2: backend-ai-gpu-agent-002 (scalable)                   â”‚
â”‚  â””â”€â”€ VM N: backend-ai-gpu-agent-N                                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Physical GPU Nodes                                                â”‚
â”‚  â”œâ”€â”€ Node 1 (GPU passthrough enabled)                             â”‚
â”‚  â”œâ”€â”€ Node 2 (GPU passthrough enabled)                             â”‚
â”‚  â””â”€â”€ Node N                                                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ”§ Prerequisites

### Hardware Requirements
- **GPU Nodes**: NVIDIA GPUê°€ ì¥ì°©ëœ ì›Œì»¤ ë…¸ë“œ
- **IOMMU Support**: Intel VT-d ë˜ëŠ” AMD IOMMU ì§€ì›
- **CPU**: ìµœì†Œ 8ì½”ì–´ (VMë‹¹ 16ì½”ì–´ ê¶Œì¥)
- **Memory**: ìµœì†Œ 32GB (VMë‹¹ 64GB ê¶Œì¥)
- **Storage**: NVMe SSD ê¶Œì¥ (VM ë””ìŠ¤í¬ìš©)

### Software Requirements
- **Kubernetes**: v1.25+ (RBAC í™œì„±í™”)
- **KubeVirt**: v1.1.1+
- **CDI**: v1.58.1+
- **NVIDIA GPU Operator**: v23.9.1+
- **Helm**: v3.8+
- **Docker**: ìµœì‹  ë²„ì „

### BIOS/UEFI Configuration
```bash
# BIOSì—ì„œ í™œì„±í™” í•„ìš”
- Intel VT-x / AMD-V (Virtualization)
- Intel VT-d / AMD IOMMU (I/O Virtualization)
- SR-IOV (ì„ íƒì‚¬í•­, ê³ ì„±ëŠ¥ ë„¤íŠ¸ì›Œí‚¹ìš©)
```

### Kernel Parameters
```bash
# /etc/default/grubì— ì¶”ê°€
GRUB_CMDLINE_LINUX="intel_iommu=on vfio-pci.ids=10de:2236"  # NVIDIA A10 ì˜ˆì‹œ
# ë˜ëŠ” AMDì˜ ê²½ìš°
GRUB_CMDLINE_LINUX="amd_iommu=on vfio-pci.ids=10de:2236"

# GRUB ì—…ë°ì´íŠ¸
sudo update-grub
sudo reboot
```

## ğŸš€ Quick Start

### 1ë‹¨ê³„: ë…¸ë“œ ì¤€ë¹„ ë° ë¼ë²¨ë§

```bash
# GPU ë…¸ë“œì— ë¼ë²¨ ì¶”ê°€
kubectl label nodes <gpu-node-1> nvidia.com/gpu.workload.config=vm-passthrough
kubectl label nodes <gpu-node-1> gpu-type=a10
kubectl label nodes <gpu-node-1> node-role.kubernetes.io/worker=""

# GPU ì •ë³´ í™•ì¸
kubectl describe node <gpu-node-1>
```

### 2ë‹¨ê³„: ì „ì²´ ë°°í¬ (ìë™)

```bash
# ëª¨ë“  ì»´í¬ë„ŒíŠ¸ ë°°í¬
./deploy-kubevirt-gpu.sh deploy

# ë°°í¬ ê²€ì¦
./deploy-kubevirt-gpu.sh verify

# GPU ì ‘ê·¼ í…ŒìŠ¤íŠ¸
./deploy-kubevirt-gpu.sh test-gpu
```

### 3ë‹¨ê³„: ë°°í¬ ìƒíƒœ í™•ì¸

```bash
# KubeVirt ìƒíƒœ í™•ì¸
kubectl get kubevirt kubevirt -n kubevirt

# GPU VM ìƒíƒœ í™•ì¸
kubectl get vms -n backend-ai-gpu
kubectl get vmis -n backend-ai-gpu

# Backend.AI Agent ë¡œê·¸ í™•ì¸
kubectl logs -f -n backend-ai-gpu deployment/backend-ai-gpu-agent-001-service
```

## ğŸ“‚ Project Structure

```
backend.ai/
â”œâ”€â”€ KUBEVIRT_GPU_GUIDE.md                   # ì´ ë¬¸ì„œ
â”œâ”€â”€ kubevirt-gpu-setup.yaml                 # KubeVirt GPU ì„¤ì •
â”œâ”€â”€ backend-ai-gpu-vm.yaml                  # GPU VM ì •ì˜
â”œâ”€â”€ kubevirt-network-config.yaml            # ë„¤íŠ¸ì›Œí¬ ì„¤ì •
â”œâ”€â”€ deploy-kubevirt-gpu.sh                  # ìë™ ë°°í¬ ìŠ¤í¬ë¦½íŠ¸
â””â”€â”€ backend-ai-gpu-agent-helm/              # Helm ì°¨íŠ¸
    â”œâ”€â”€ Chart.yaml
    â”œâ”€â”€ values.yaml
    â””â”€â”€ templates/
        â”œâ”€â”€ virtualmachine.yaml
        â”œâ”€â”€ service.yaml
        â”œâ”€â”€ configmap.yaml
        â””â”€â”€ ...
```

## ğŸ”¨ Manual Deployment Steps

ìë™ ë°°í¬ ìŠ¤í¬ë¦½íŠ¸ë¥¼ ì‚¬ìš©í•˜ì§€ ì•Šê³  ìˆ˜ë™ìœ¼ë¡œ ë°°í¬í•˜ëŠ” ê²½ìš°:

### 1. KubeVirt ì„¤ì¹˜

```bash
# KubeVirt Operator ì„¤ì¹˜
kubectl apply -f https://github.com/kubevirt/kubevirt/releases/download/v1.1.1/kubevirt-operator.yaml

# KubeVirt CR ì„¤ì¹˜
kubectl apply -f https://github.com/kubevirt/kubevirt/releases/download/v1.1.1/kubevirt-cr.yaml

# GPU ì„¤ì • ì ìš©
kubectl apply -f kubevirt-gpu-setup.yaml

# ì„¤ì¹˜ í™•ì¸
kubectl wait --for=condition=Available kubevirt kubevirt -n kubevirt --timeout=600s
```

### 2. CDI ì„¤ì¹˜

```bash
# CDI Operator ì„¤ì¹˜
kubectl apply -f https://github.com/kubevirt/containerized-data-importer/releases/download/v1.58.1/cdi-operator.yaml

# CDI CR ì„¤ì¹˜
kubectl apply -f https://github.com/kubevirt/containerized-data-importer/releases/download/v1.58.1/cdi-cr.yaml

# ì„¤ì¹˜ í™•ì¸
kubectl wait --for=condition=Available cdi cdi -n cdi --timeout=300s
```

### 3. NVIDIA GPU Operator ì„¤ì¹˜

```bash
# NVIDIA Helm Repository ì¶”ê°€
helm repo add nvidia https://helm.ngc.nvidia.com/nvidia
helm repo update

# GPU Operator ì„¤ì¹˜
kubectl create namespace gpu-operator
helm install gpu-operator nvidia/gpu-operator \
  --namespace gpu-operator \
  --set sandboxWorkloads.enabled=true \
  --set toolkit.enabled=true \
  --set driver.enabled=true \
  --set migManager.enabled=false
```

### 4. ë„¤íŠ¸ì›Œí‚¹ ì„¤ì •

```bash
# Multus CNI ì„¤ì¹˜
kubectl apply -f https://raw.githubusercontent.com/k8snetworkplumbingwg/multus-cni/master/deployments/multus-daemonset.yml

# ë„¤íŠ¸ì›Œí¬ ì„¤ì • ì ìš©
kubectl apply -f kubevirt-network-config.yaml
```

### 5. GPU Base Image ë¹Œë“œ

```bash
# Harbor ë¡œê·¸ì¸
docker login localhost:30002 -u admin -p Harbor12345

# GPU Base Image ë¹Œë“œ ë° í‘¸ì‹œ
docker build -f Dockerfile.ubuntu-gpu -t localhost:30002/backend-ai/ubuntu-gpu:22.04 .
docker push localhost:30002/backend-ai/ubuntu-gpu:22.04
```

### 6. Backend.AI GPU Agent VM ë°°í¬

```bash
# ë„¤ì„ìŠ¤í˜ì´ìŠ¤ ìƒì„±
kubectl create namespace backend-ai-gpu

# Registry Secret ìƒì„±
kubectl create secret docker-registry harbor-registry-secret \
    --docker-server=localhost:30002 \
    --docker-username=admin \
    --docker-password=Harbor12345 \
    -n backend-ai-gpu

# Helmìœ¼ë¡œ GPU Agent ë°°í¬
helm install backend-ai-gpu-agents ./backend-ai-gpu-agent-helm \
    --namespace backend-ai-gpu \
    --set vm.replicas=2 \
    --set vm.resources.gpu.enabled=true
```

## ğŸ¯ Management Commands

### VM ê´€ë¦¬

```bash
# VM ìƒíƒœ í™•ì¸
kubectl get vms -n backend-ai-gpu
kubectl get vmis -n backend-ai-gpu

# VM ì‹œì‘/ì¤‘ì§€
kubectl patch vm backend-ai-gpu-agent-001 -n backend-ai-gpu --type merge -p '{"spec":{"running":true}}'
kubectl patch vm backend-ai-gpu-agent-001 -n backend-ai-gpu --type merge -p '{"spec":{"running":false}}'

# VM ì½˜ì†” ì ‘ê·¼ (virtctl í•„ìš”)
virtctl console -n backend-ai-gpu backend-ai-gpu-agent-001

# VM SSH ì ‘ê·¼ (VM ë‚´ë¶€ì—ì„œ SSH ì„¤ì • í›„)
kubectl port-forward -n backend-ai-gpu svc/backend-ai-gpu-agent-001-service 2222:22
ssh backend-ai@localhost -p 2222
```

### Scaling

```bash
# VM ê°œìˆ˜ ì¡°ì •
helm upgrade backend-ai-gpu-agents ./backend-ai-gpu-agent-helm \
    --namespace backend-ai-gpu \
    --set vm.replicas=5

# íŠ¹ì • GPU íƒ€ì…ìœ¼ë¡œ ë°°í¬
helm upgrade backend-ai-gpu-agents ./backend-ai-gpu-agent-helm \
    --namespace backend-ai-gpu \
    --set vm.nodeSelector."gpu-type"="v100" \
    --set vm.resources.gpu.devices[0].deviceName="nvidia.com/GV100GL_Tesla_V100"
```

### ëª¨ë‹ˆí„°ë§

```bash
# VM ë¦¬ì†ŒìŠ¤ ì‚¬ìš©ëŸ‰
kubectl top pods -n backend-ai-gpu

# GPU ì‚¬ìš©ë¥  í™•ì¸
kubectl exec -n backend-ai-gpu virt-launcher-backend-ai-gpu-agent-001 -- nvidia-smi

# VM ì´ë²¤íŠ¸ í™•ì¸
kubectl get events -n backend-ai-gpu --sort-by=.metadata.creationTimestamp

# Backend.AI Agent ë¡œê·¸
kubectl logs -f -n backend-ai-gpu <virt-launcher-pod-name> -c compute
```

## ğŸ” Troubleshooting

### Common Issues

#### 1. VMì´ ì‹œì‘ë˜ì§€ ì•ŠìŒ

```bash
# VM ì´ë²¤íŠ¸ í™•ì¸
kubectl describe vm backend-ai-gpu-agent-001 -n backend-ai-gpu

# VMI ìƒíƒœ í™•ì¸
kubectl describe vmi backend-ai-gpu-agent-001 -n backend-ai-gpu

# ê°€ëŠ¥í•œ ì›ì¸:
# - GPU ë…¸ë“œì— ì¶©ë¶„í•œ ë¦¬ì†ŒìŠ¤ê°€ ì—†ìŒ
# - GPU ë””ë°”ì´ìŠ¤ê°€ ì´ë¯¸ ì‚¬ìš© ì¤‘
# - ì´ë¯¸ì§€ í’€ ì‹¤íŒ¨
```

#### 2. GPU Passthrough ì‹¤íŒ¨

```bash
# GPU ë…¸ë“œ ìƒíƒœ í™•ì¸
kubectl describe node <gpu-node-name>

# VFIO-PCI ë“œë¼ì´ë²„ í™•ì¸
lspci -nnk -d 10de:

# IOMMU ê·¸ë£¹ í™•ì¸
find /sys/kernel/iommu_groups/ -type l | grep <gpu-pci-id>

# í•´ê²° ë°©ë²•:
# - BIOSì—ì„œ IOMMU í™œì„±í™” í™•ì¸
# - Kernel íŒŒë¼ë¯¸í„° í™•ì¸
# - GPU ë“œë¼ì´ë²„ ë°”ì¸ë”© í™•ì¸
```

#### 3. ë„¤íŠ¸ì›Œí¬ ì—°ê²° ë¬¸ì œ

```bash
# ë„¤íŠ¸ì›Œí¬ ì„¤ì • í™•ì¸
kubectl get networkattachmentdefinition -n backend-ai-gpu

# Pod ë„¤íŠ¸ì›Œí¬ ì¸í„°í˜ì´ìŠ¤ í™•ì¸
kubectl exec -n backend-ai-gpu <virt-launcher-pod> -- ip addr show

# Manager-Agent ì—°ê²° í…ŒìŠ¤íŠ¸
kubectl exec -n backend-ai-gpu <virt-launcher-pod> -- ping backend-ai-etcd.backend-ai.svc.cluster.local
```

#### 4. Backend.AI Agent ì—°ê²° ì‹¤íŒ¨

```bash
# Agent ì„¤ì • í™•ì¸
kubectl exec -n backend-ai-gpu <virt-launcher-pod> -- cat /etc/backend.ai/agent.toml

# ETCD ì—°ê²° í…ŒìŠ¤íŠ¸
kubectl exec -n backend-ai-gpu <virt-launcher-pod> -- curl -v http://backend-ai-etcd.backend-ai.svc.cluster.local:2379/health

# Agent ì„œë¹„ìŠ¤ ìƒíƒœ
kubectl exec -n backend-ai-gpu <virt-launcher-pod> -- systemctl status backend-ai-agent
```

### Log Collection

```bash
# ëª¨ë“  KubeVirt ë¡œê·¸ ìˆ˜ì§‘
kubectl logs -n kubevirt -l kubevirt.io=virt-operator > kubevirt-operator.log

# GPU VM ë¡œê·¸ ìˆ˜ì§‘
kubectl logs -n backend-ai-gpu <virt-launcher-pod-name> > gpu-vm.log

# GPU Operator ë¡œê·¸ ìˆ˜ì§‘
kubectl logs -n gpu-operator -l app=nvidia-operator-validator > gpu-operator.log
```

## ğŸ›¡ï¸ Security Considerations

### GPU Resource Isolation
- VFIO-PCI ë“œë¼ì´ë²„ë¥¼ í†µí•œ í•˜ë“œì›¨ì–´ ê²©ë¦¬
- IOMMUë¥¼ í†µí•œ ë©”ëª¨ë¦¬ ë³´í˜¸
- VMê°„ GPU ë¦¬ì†ŒìŠ¤ ì™„ì „ ë¶„ë¦¬

### Network Security
- VMë³„ ë³„ë„ ë„¤íŠ¸ì›Œí¬ ë„¤ì„ìŠ¤í˜ì´ìŠ¤
- Network Policyë¥¼ í†µí•œ íŠ¸ë˜í”½ ì œì–´
- ê´€ë¦¬ ë„¤íŠ¸ì›Œí¬ì™€ ë°ì´í„° ë„¤íŠ¸ì›Œí¬ ë¶„ë¦¬

### Access Control
- RBACë¥¼ í†µí•œ ì„¸ë°€í•œ ê¶Œí•œ ì œì–´
- VM ì½˜ì†” ì ‘ê·¼ ì œí•œ
- SSH Key ê¸°ë°˜ ì¸ì¦

## ğŸ“Š Performance Optimization

### CPU ìµœì í™”
```yaml
# CPU Pinning ì„¤ì •
cpu:
  dedicatedCpuPlacement: true
  numa:
    guestMappingPassthrough: {}
```

### Memory ìµœì í™”
```yaml
# Huge Pages ì‚¬ìš©
memory:
  guest: 64Gi
  hugepages:
    pageSize: 2Mi
```

### Storage ìµœì í™”
```yaml
# NVMe SSD ì‚¬ìš©
storageClassName: fast-nvme-ssd
```

### Network ìµœì í™”
```yaml
# SR-IOV ì‚¬ìš© (ê³ ì„±ëŠ¥ ì›Œí¬ë¡œë“œìš©)
networks:
- name: sriov-net
  multus:
    networkName: backend-ai-gpu-sriov-net
```

## ğŸ”„ Backup and Recovery

### VM ìŠ¤ëƒ…ìƒ·
```bash
# VM ìŠ¤ëƒ…ìƒ· ìƒì„±
kubectl apply -f - <<EOF
apiVersion: snapshot.kubevirt.io/v1alpha1
kind: VirtualMachineSnapshot
metadata:
  name: gpu-agent-snapshot
  namespace: backend-ai-gpu
spec:
  source:
    apiVersion: kubevirt.io/v1
    kind: VirtualMachine
    name: backend-ai-gpu-agent-001
EOF

# ìŠ¤ëƒ…ìƒ·ì—ì„œ ë³µì›
kubectl apply -f - <<EOF
apiVersion: snapshot.kubevirt.io/v1alpha1
kind: VirtualMachineRestore
metadata:
  name: gpu-agent-restore
  namespace: backend-ai-gpu
spec:
  target:
    apiVersion: kubevirt.io/v1
    kind: VirtualMachine
    name: backend-ai-gpu-agent-001-restored
  virtualMachineSnapshotName: gpu-agent-snapshot
EOF
```

### ì„¤ì • ë°±ì—…
```bash
# VM ì •ì˜ ë°±ì—…
kubectl get vm -n backend-ai-gpu -o yaml > gpu-vms-backup.yaml

# ë„¤íŠ¸ì›Œí¬ ì„¤ì • ë°±ì—…
kubectl get networkattachmentdefinition -n backend-ai-gpu -o yaml > network-backup.yaml

# Helm ê°’ ë°±ì—…
helm get values backend-ai-gpu-agents -n backend-ai-gpu > gpu-agent-values.yaml
```

## ğŸš« Cleanup

### VM ì œê±°
```bash
# Helmìœ¼ë¡œ GPU Agent ì œê±°
helm uninstall backend-ai-gpu-agents -n backend-ai-gpu

# ë„¤ì„ìŠ¤í˜ì´ìŠ¤ ì œê±°
kubectl delete namespace backend-ai-gpu
```

### ì™„ì „ ì •ë¦¬
```bash
# ì „ì²´ ì •ë¦¬ ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰
./deploy-kubevirt-gpu.sh cleanup

# ìˆ˜ë™ ì •ë¦¬
kubectl delete namespace backend-ai-gpu
kubectl delete namespace gpu-operator
# KubeVirtì™€ CDIëŠ” ë‹¤ë¥¸ ì›Œí¬ë¡œë“œê°€ ì‚¬ìš©í•  ìˆ˜ ìˆìœ¼ë¯€ë¡œ ì‹ ì¤‘í•˜ê²Œ ì œê±°
```

## ğŸ“š Additional Resources

### Documentation
- [KubeVirt User Guide](https://kubevirt.io/user-guide/)
- [NVIDIA GPU Operator](https://docs.nvidia.com/datacenter/cloud-native/gpu-operator/overview.html)
- [Backend.AI Documentation](https://docs.backend.ai/)

### Tools
- [virtctl CLI](https://kubevirt.io/user-guide/operations/virtctl_client_tool/) - VM ê´€ë¦¬ ë„êµ¬
- [CDI CLI](https://github.com/kubevirt/containerized-data-importer) - ë°ì´í„° ë³¼ë¥¨ ê´€ë¦¬

### Examples
- GPU VM í…œí”Œë¦¿: `backend-ai-gpu-vm.yaml`
- Helm ì°¨íŠ¸: `backend-ai-gpu-agent-helm/`
- ë„¤íŠ¸ì›Œí¬ ì„¤ì •: `kubevirt-network-config.yaml`

---

## ğŸ’¡ Best Practices

### Development Environment
- ë‹¨ì¼ GPU ë…¸ë“œë¡œ ì‹œì‘í•˜ì—¬ ì ì§„ì  í™•ì¥
- ë¦¬ì†ŒìŠ¤ ì œí•œì„ í†µí•œ ë©€í‹°í…Œë„Œì‹œ êµ¬í˜„
- ê°œë°œ/í…ŒìŠ¤íŠ¸ìš© ì‘ì€ VM ì‚¬ì´ì¦ˆ ì‚¬ìš©

### Production Environment
- ê³ ê°€ìš©ì„±ì„ ìœ„í•œ ë‹¤ì¤‘ GPU ë…¸ë“œ
- ìë™ ìŠ¤ì¼€ì¼ë§ ì •ì±… êµ¬ì„±
- ëª¨ë‹ˆí„°ë§ ë° ì•ŒëŒ ì‹œìŠ¤í…œ êµ¬ì¶•
- ì •ê¸°ì ì¸ ë°±ì—… ìŠ¤ì¼€ì¤„

### Cost Optimization
- GPU ì‚¬ìš©ë¥  ëª¨ë‹ˆí„°ë§ì„ í†µí•œ ì ì • VM í¬ê¸° ì¡°ì •
- Spot Instance í™œìš© (í´ë¼ìš°ë“œ í™˜ê²½)
- ìœ íœ´ ì‹œê°„ VM ìë™ ì¢…ë£Œ

---

## â“ Support

ë¬¸ì œê°€ ë°œìƒí•˜ê±°ë‚˜ ì§ˆë¬¸ì´ ìˆìœ¼ì‹œë©´:

1. **ë¡œê·¸ ìˆ˜ì§‘**: ìœ„ì˜ "Log Collection" ì„¹ì…˜ ì°¸ê³ 
2. **GitHub Issues**: KubeVirt, Backend.AI í”„ë¡œì íŠ¸ì— ì´ìŠˆ ë“±ë¡
3. **ì»¤ë®¤ë‹ˆí‹°**: 
   - KubeVirt Slack: kubernetes.slack.com #kubevirt
   - Backend.AI ì»¤ë®¤ë‹ˆí‹° í¬ëŸ¼

**Happy GPU Virtualization! ğŸ®ğŸš€**